{"name":"yuicompressor-server","tagline":"Simple HTTP service with an embeded yuicompressor engine","body":"yuicompressor-server\r\n====================\r\n\r\nA pure java HTTP service with an embeded yuicompressor engine\r\n\r\n[![Build Status](https://travis-ci.org/kpacha/yuicompressor-server.png?branch=master)](https://travis-ci.org/kpacha/yuicompressor-server)\r\n\r\nPowered by [jetty](http://www.eclipse.org/jetty/), [ehcache](http://ehcache.org/) and [yui-compressor](http://yui.github.com/yuicompressor/) and inspired on [fotonaut's yuicompressor-server](https://github.com/fotonauts/yuicompressor-server/)\r\n\r\n#Requirements\r\n\r\n* git\r\n* jdk 1.7\r\n* mvn 3\r\n\r\n#Install\r\n\r\nClone the project and install it!\r\n\r\n\t$ git clone https://github.com/kpacha/yuicompressor-server.git\r\n\t$ cd yuicompressor-server\r\n\t$ mvn install\r\n\r\nAnd, after testing the code, the yuicompressor-server-0.2.0-SNAPSHOT.jar should be on your local maven repo\r\n\r\n#Run with maven\r\n\r\nIf the first test is hard, people usually quit the test... So check this out! Just type one more maven command and done! \r\n\r\n\t$ mvn clean compile exec:java\r\n\r\nYour service should be waiting for you at port `8080`. Nice, uh?\r\n\r\n#Build and Run the fat-jar\r\n\r\nSo, let's build it for real, deploy it to an actual server and run it!\r\n\r\n\t$ mvn clean compile assembly:single\r\n\t# ...and you are ready for deploy the fat-jar!\r\n\r\n\t# ... your deployment process here ...\r\n\r\n\t# start the yuicompressor service\r\n\t$ java -jar target/yuicompressor-server-0.2.0-SNAPSHOT-jar-with-dependencies.jar [<PORT> [<ALGORITHM>]]\r\n\r\nNote the optional arguments!\r\n\r\n* `PORT` allows you to set the service port. Default value is `8080`\r\n* `ALGORITHM` allows you to set the hashing algorithm. Default: `SHA-1`\r\n\r\nAnd you already have a yuicompressor-server running!\r\n\r\n#Usage\r\n\r\nJust send your javascript and css files as a post request to your service.\r\n\r\nSimple demo with curl:\r\n\r\n\t$ curl -H \"Content-Type:text/css; charset=utf-8\" -X POST -id 'a {}       c{ color=red;      }' http://localhost:8080/\r\n\t# or\r\n\t$ curl -H \"Content-Type:text/css; charset=utf-8\" -X POST -id @src/test/resources/test.css http://localhost:8080/\r\n\r\nDo not forget to set the `Content-Type` header with the right charset or get ready to die a painful, lonely death!\r\n\r\n#Why?\r\n\r\nSupose you have several hosts where you have to compress your javascript and css files. Why would you spend so much time doing the same operation again and again? And are your files different from one host to another or are they almost the same? How often do you deploy? Just take the DRY pattern to the next abstraction level and delegate that process to a dedicated service!\r\n\r\n\t$ cd src/test/resources\r\n\t$ ab -c 10 -n 100 -H \"Content-Type:text/css; charset=utf-8\" -p test.css -T \"text/css\" http://localhost:8080/\r\n\tThis is ApacheBench, Version 2.3 <$Revision: 1430300 $>\r\n\tCopyright 1996 Adam Twiss, Zeus Technology Ltd, http://www.zeustech.net/\r\n\tLicensed to The Apache Software Foundation, http://www.apache.org/\r\n\r\n\tBenchmarking localhost (be patient).....done\r\n\r\n\r\n\tServer Software:        Jetty(9.1.z-SNAPSHOT)\r\n\tServer Hostname:        localhost\r\n\tServer Port:            8080\r\n\r\n\tDocument Path:          /\r\n\tDocument Length:        52 bytes\r\n\r\n\tConcurrency Level:      10\r\n\tTime taken for tests:   0.087 seconds\r\n\tComplete requests:      100\r\n\tFailed requests:        0\r\n\tWrite errors:           0\r\n\tTotal transferred:      27900 bytes\r\n\tTotal body sent:        22900\r\n\tHTML transferred:       5200 bytes\r\n\tRequests per second:    1143.80 [#/sec] (mean)\r\n\tTime per request:       8.743 [ms] (mean)\r\n\tTime per request:       0.874 [ms] (mean, across all concurrent requests)\r\n\tTransfer rate:          311.64 [Kbytes/sec] received\r\n\t                        255.79 kb/s sent\r\n\t                        567.43 kb/s total\r\n\r\n\tConnection Times (ms)\r\n\t              min  mean[+/-sd] median   max\r\n\tConnect:        0    0   0.5      0       2\r\n\tProcessing:     2    8   4.9      7      31\r\n\tWaiting:        2    8   4.6      7      31\r\n\tTotal:          2    8   5.0      7      31\r\n\r\n\tPercentage of the requests served within a certain time (ms)\r\n\t  50%      7\r\n\t  66%      8\r\n\t  75%     10\r\n\t  80%     12\r\n\t  90%     16\r\n\t  95%     19\r\n\t  98%     23\r\n\t  99%     31\r\n\t 100%     31 (longest request)\r\n\r\n\r\n\r\nWas that enough?\r\n\r\n[![Bitdeli Badge](https://d2weczhvl823v0.cloudfront.net/kpacha/yuicompressor-server/trend.png)](https://bitdeli.com/free \"Bitdeli Badge\")","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}